{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic differential equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggested references:\n",
    "\n",
    "* C Gardiner, *Stochastic Methods: A Handbook for the Natural and Social Sciences*, Springer.\n",
    "* D Higham, *An algorithmic introduction to Stochastic Differential Equations*, SIAM Review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kostas Zygalakis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick recap: the key feature is the *Ito stochastic integral*\n",
    "\n",
    "\\begin{equation}\n",
    "  \\int_{t_0}^t G(t') \\, dW(t') = \\text{mean-square-}\\lim_{n\\to +\\infty} \\left\\{ \\sum_{i=1}^n G(t_{i-1}) (W_{t_i} - W_{t_{i-1}} \\right\\}\n",
    "\\end{equation}\n",
    "\n",
    "where the key point for the Ito integral is that the first term in the sum is evaluated at the left end of the interval ($t_{i-1}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use this to write down the SDE\n",
    "\n",
    "\\begin{equation}\n",
    "  dX_t = f(X_t) \\, dt + g(X_t) \\, dW_t\n",
    "\\end{equation}\n",
    "\n",
    "with formal solution\n",
    "\n",
    "\\begin{equation}\n",
    "  X_t = X_0 + \\int_0^t f(X_s) \\, ds + \\int_0^t g(X_s) \\, dW_s.\n",
    "\\end{equation}\n",
    "\n",
    "Using the Ito stochastic integral formula we get the Euler-Maruyama method\n",
    "\n",
    "\\begin{equation}\n",
    " X_{n+1} = X_n + h f(X_n) + \\sqrt{h} \\xi_n \\, g(X_n)\n",
    "\\end{equation}\n",
    "\n",
    "by applying the integral over the region $[t_n, t_{n+1} = t_n + h]$. Here $h$ is the width of the interval and $\\xi_n$ is the normal random variable $\\xi_n \\sim N(0, 1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order of accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to talk about errors here. It depends on the *realization* that you have. That is, for each realization there is a different Brownian path $W$. \n",
    "\n",
    "If we fix to one realization - a single Brownian path $W$ - then we can vary the size of the step $h$. This gives us the *strong* order of convergence: how the error varies with $h$ for a *fixed* Brownian path.\n",
    "\n",
    "The other question is what happens when we consider the average of all possible realizations. This is the *weak* order of convergence.\n",
    "\n",
    "Formally, denote the true solution as $X(T)$ and the numerical solution for a given step length $h$ as $X^h(T)$. The order of convergence is denoted $\\gamma$.\n",
    "\n",
    "#### Strong convergence\n",
    "\n",
    "\\begin{equation}\n",
    "  \\mathbb{E} \\left| X(T) - X^h(T) \\right| \\le C h^{\\gamma}\n",
    "\\end{equation}\n",
    "\n",
    "#### Weak convergence\n",
    "\n",
    "\\begin{equation}\n",
    "  \\left| \\mathbb{E} \\left( \\phi( X(T) ) \\right) - \\mathbb{E} \\left( \\phi( X^h(T) ) \\right) \\right| \\le C h^{\\gamma}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Euler-Maruyama, the weak order of convergence is 1 (as you would expect from the name). *However*, the strong order of convergence is 1/2. Intuitively this is related to the $\\sqrt{h}$ factor in the Brownian path.\n",
    "\n",
    "##### Catch\n",
    "\n",
    "If $g'(X) \\ne 0$ the strong convergence is 1/2, otherwise it is 1!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic chain rule\n",
    "\n",
    "For our purposes we just need that $dW^2 = dt$ (from our definition of the Brownian path - changing notation for the increment from $h$ to $dt$), which means that (by only keeping leading order terms) $dW^{2+N} = 0$ for all $N > 0$. The higher moments vary too fast to contribute to anything on the timescales that we're interested in, after averaging.\n",
    "\n",
    "### Normal chain rule\n",
    "\n",
    "If\n",
    "\n",
    "\\begin{equation}\n",
    "  \\frac{dX}{dt} = f(X_t)\n",
    "\\end{equation}\n",
    "\n",
    "and we want to find the differential equation satisfied by $h(X(t))$ (or $h(X_t)$), then we write\n",
    "\n",
    "\\begin{align}\n",
    "  &&\\frac{d}{dt} h(X_t) &= h \\left( X(t) + dX(t) \\right) - h(X(t)) \\\\\n",
    "  &&&\\simeq h(X(t)) + dX \\, h'(X(t)) + \\frac{1}{2} (dX)^2 \\, h''(X(t)) + \\dots - h(X(t)) \\\\\n",
    "  &&&\\simeq f(X) h'(X) dt + \\frac{1}{2} (f(X))^2 h''(X) (dt)^2 + \\dots \\\\\n",
    "  \\implies && \\frac{d h(X)}{dt} &= f(X) h'(X).\n",
    "\\end{align}\n",
    "\n",
    "### Stochastic chain rule\n",
    "\n",
    "Now run through the same steps using the equation\n",
    "\n",
    "\\begin{equation}\n",
    "  dX = f(X)\\, dt + g(X) \\, dW.\n",
    "\\end{equation}\n",
    "\n",
    "We find\n",
    "\n",
    "\\begin{align}\n",
    "  && d h &\\simeq h'(X(t))\\, dX + \\frac{1}{2} h''(X(t)) (dX)^2 + \\dots, \\\\\n",
    "  &&&\\simeq h'(X) f(X)\\, dt + h'(X) g(X) ', dW + \\frac{1}{2} \\left( f(X) dt^2 + 2 f(x)g(x)\\, dt dW + g^2(x) dW^2 \\right) \\\\\n",
    "  \\implies && d h &= \\left( f(X) h'(X) + \\frac{1}{2} h''(X)g^2(X) \\right) \\, dt + h'(X) g(X) \\, dW.\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This additional $g^2$ term makes all the difference when deriving numerical methods, where the chain rule is repeatedly used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using this result\n",
    "\n",
    "Remember that\n",
    "\n",
    "\\begin{equation}\n",
    "  \\int_{t_0}^t W_s \\, dW_s = \\frac{1}{2} W^2_t - \\frac{1}{2} W^2_{t_0} - \\frac{1}{2} (t - t_0).\n",
    "\\end{equation}\n",
    "\n",
    "From this we need to identify the stochastic differential equation, and also the function $h$, that will give us this result just from the chain rule.\n",
    "\n",
    "The SDE is\n",
    "\n",
    "\\begin{equation}\n",
    "  dX_t = dW_t, \\quad f(X) = 0, \\quad g(X) = 1.\n",
    "\\end{equation}\n",
    "\n",
    "Writing the chain rule down in the form\n",
    "\n",
    "\\begin{equation}\n",
    "  h(X_t) = h(X_0) + \\int_0^t \\left( f(X_s) h'(X_s) + \\frac{1}{2} h''(X_s) g^2(X_s) \\right) \\, dt + \\int_0^t h'(X_s) g(X_s) \\, dW_s.\n",
    "\\end{equation}\n",
    "\n",
    "Matching the final term (the integral over $dW_s$) we see that we need $h'$ to go like $X$, or \n",
    "\n",
    "\\begin{equation}\n",
    "  h = X^2, \\quad dX_t = dW_t, \\quad f(X) = 0, \\quad g(X) = 1.\n",
    "\\end{equation}\n",
    "\n",
    "With $X_t = W_t$ we therefore have\n",
    "\n",
    "\\begin{align}\n",
    "   W_t^2 &= W_0^2 + \\int_{t_0}^t \\frac{1}{2} 2 \\, ds + \\int_{t_0}^t 2 W_s \\, dW_s\n",
    "   &= W_0^2 + (t - t_0) + \\int_{t_0}^t 2 W_s \\, dW_s\n",
    "\\end{align}\n",
    "\n",
    "as required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise\n",
    "\n",
    "Given\n",
    "\n",
    "\\begin{equation}\n",
    "  dX_t = \\lambda X_t \\, dt + \\mu X_t \\, dW_t, \\quad h(X) = \\log(X),\n",
    "\\end{equation}\n",
    "\n",
    "prove that\n",
    "\n",
    "\\begin{equation}\n",
    "  X(t) = X(0) e^{(\\lambda - \\tfrac{1}{2} \\mu^2) t + \\mu W_t}.\n",
    "\\end{equation}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
